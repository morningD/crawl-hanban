{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hanban_crawler.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "38KKDeGelMu-",
        "colab_type": "code",
        "outputId": "ed08499b-c7c7-43f5-9d5a-bb37139a396f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install beautifulsoup4"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (4.6.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8waytza7z4CX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import urllib.request\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from bs4 import BeautifulSoup,Comment\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7j6dACpB1pfy",
        "colab_type": "code",
        "outputId": "808d94e9-c4ea-45e6-a506-9ab681428818",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "url = \"http://www.hanban.org/hanbancn/template/ciotab_cn1.htm?v1\"\n",
        "response = urllib.request.urlopen(url)\n",
        "#webContent = response.read().decode(response.headers.get_content_charset())\n",
        "webContent = response.read().decode(\"utf-8\")\n",
        "print(len(webContent))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "233918\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czY_lHHrmDhx",
        "colab_type": "code",
        "outputId": "1ff46dd5-97c5-4d05-a553-efb802f3a753",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# info_dict->{name:{'country', 'city', 'type', 'date', 'status', 'url'}}\n",
        "info_dict = {}\n",
        "\n",
        "tabContent = BeautifulSoup(webContent).find(\"div\", class_=\"tabContent\")\n",
        "continents = tabContent.find_all(\"div\", class_=\"tcon\")\n",
        "\n",
        "for con in continents:\n",
        "  # 得到此大洲国家名的box\n",
        "  nations = con.find(\"div\", class_=re.compile(r\"nation\\d*\"))\n",
        "  \n",
        "  # 去掉被注释的国家\n",
        "  for comment_country in nations(text=lambda text: isinstance(text, Comment)):\n",
        "    comment_country.extract()\n",
        "  # 得到此大洲国家列表\n",
        "  counties = [c.string for c in nations.find_all(\"a\")]\n",
        "  \n",
        "  # 得到此大洲的学校box\n",
        "  schools = con.find(\"div\", class_=re.compile(\"tcon_nationBox\\d*\"))\n",
        "  # 得到此大洲里各个国家的学校tab\n",
        "  # find_all()会忽视被注释的tab，不需要再去掉注释\n",
        "  schools_nation = schools.find_all(\"div\", class_=\"tcon_nation\")\n",
        "  \n",
        "  # 确认国家列表与学校列表是对应的\n",
        "  if len(schools_nation) != len(counties):\n",
        "    print(\"ERROR: schools tab no match the country.\")\n",
        "    break\n",
        "  \n",
        "  # 处理各个国家的学校\n",
        "  for idx, sc in enumerate(counties):\n",
        "    # 处理孔子学院\n",
        "    kys = schools_nation[idx].find(\"div\", class_=\"KY\")\n",
        "    # 检查是否有被注释的学院\n",
        "    comment_kys = kys.find_all(string=lambda text: isinstance(text, Comment))\n",
        "    # 处理被注释的学院\n",
        "    if comment_kys:\n",
        "      for ckys in comment_kys:\n",
        "        # 由于注释没有建树，所以需要在创建一个BeautifulSoup进行解析\n",
        "        ckys_bs = BeautifulSoup(ckys)\n",
        "        for cky in ckys_bs.find_all(\"a\"):\n",
        "          ky_name = cky.string\n",
        "          if ky_name:\n",
        "            ky_name = ky_name.strip()\n",
        "            ky_url = cky.get(\"href\") or \"NaN\"\n",
        "            info_dict[ky_name] = {'type':\"孔子学院\", 'country':counties[idx], 'status': 'hide', 'url':ky_url}\n",
        "\n",
        "    # 处理没有被注释的学院, 如果名字相同会覆盖\n",
        "    kys = kys.find_all(\"a\")\n",
        "    # 处理每个学院\n",
        "    for ky in kys:\n",
        "      ky_name = ky.string\n",
        "      if ky_name:\n",
        "        ky_name = ky_name.strip()\n",
        "        ky_url = ky.get(\"href\") or \"NaN\"\n",
        "        #ky_id = re.findall(r'\\d+', ky_url.split('/')[-1])[0]\n",
        "        # 将信息保存到汇总字典中\n",
        "        info_dict[ky_name] = {'type':\"孔子学院\", 'country':counties[idx], 'status': 'show', 'url':ky_url}\n",
        "    \n",
        "    # 处理孔子课堂\n",
        "    coures = schools_nation[idx].find(\"div\", class_=\"coures\")\n",
        "    # 检查是否有被注释的课堂\n",
        "    comment_coures = coures.find_all(string=lambda text: isinstance(text, Comment))\n",
        "    # 处理被注释的课堂\n",
        "    if comment_coures:\n",
        "      for ccoures in comment_coures:\n",
        "        # 由于注释没有建树，所以需要在创建一个BeautifulSoup进行解析\n",
        "        ccoures_bs = BeautifulSoup(ccoures)\n",
        "        for ccoure in ccoures_bs.find_all(\"a\"):\n",
        "          coure_name = ccoure.string\n",
        "          if coure_name:\n",
        "            coure_name = coure_name.strip()\n",
        "            coure_url = ccoure.get(\"href\") or \"NaN\"\n",
        "            info_dict[coure_name] = {'type':\"孔子课堂\", 'country':counties[idx], 'status': 'hide', 'url':coure_url}\n",
        "\n",
        "    # 处理没有被注释的课题\n",
        "    coures = coures.find_all(\"a\")\n",
        "    # 处理每个课堂\n",
        "    for coure in coures:\n",
        "      coure_name = coure.string\n",
        "      if coure_name:\n",
        "        coure_name = coure_name.strip()\n",
        "        coure_url = coure.get(\"href\") or \"NaN\"\n",
        "        #coure_id = re.findall(r'\\d+', coure_url.split('/')[-1])[0]\n",
        "        info_dict[coure_name] = {'type':\"孔子课堂\", 'country':counties[idx], 'status': 'show', 'url':coure_url}\n",
        "\n",
        "print(len(info_dict))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1356\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOHa5rUGv3r2",
        "colab_type": "code",
        "outputId": "25dc313b-c992-4b40-b3f2-141c4c49efef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(info_dict[\"伊利诺伊大学香槟分校孔子学院\"])\n",
        "print(info_dict[\"北佛罗里达大学孔子学院\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'type': '孔子学院', 'country': '美国', 'status': 'hide', 'url': 'http://www.hanban.org/confuciousinstitutes/node_40583.htm'}\n",
            "{'type': '孔子学院', 'country': '美国', 'status': 'hide', 'url': 'http://www.hanban.org/confuciousinstitutes/node_45557.htm '}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPPDyZiH9EMX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 爬取所有子页面内容，保存到一个字典中\n",
        "subsite_dict = {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UThmHLqyEewf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def is_url(string_url):\n",
        "  urls = re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\), ]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', string_url)\n",
        "  return urls\n",
        "\n",
        "for idx, name in enumerate(info_dict.keys()):\n",
        "  if is_url(info_dict[name]['url']) and name not in subsite_dict:\n",
        "    # 爬取页面，如果中断则继续\n",
        "    print(idx, \"\\tHandling:\", name, \"\\turl:\", info_dict[name]['url'])\n",
        "    response = urllib.request.urlopen(info_dict[name]['url'])\n",
        "    subwebContent = response.read().decode(\"utf-8\")\n",
        "    subsite_dict[name] = subwebContent"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8k3ZeSjGtxvD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 解析各个孔子学院和孔子课题url中的\"城市\"和\"创立时间\"\n",
        "for idx, name in enumerate(info_dict.keys()):\n",
        "  \n",
        "  print(idx, \"\\tHandling:\", name)\n",
        "\n",
        "  # 默认NaN\n",
        "  info_dict[name]['city'] = \"NaN\"\n",
        "  info_dict[name]['date'] = \"NaN\"\n",
        "  \n",
        "  # 处理没有爬取到内容的情况\n",
        "  if not subsite_dict[name]:\n",
        "    print(\"Skip1\", name)\n",
        "    continue\n",
        "\n",
        "  # 创建解析器\n",
        "  bs = BeautifulSoup(subsite_dict[name])\n",
        "  \n",
        "  # 有两种格式：<p>和<tbody>\n",
        "  if bs.find(\"table\"):\n",
        "    all_info = bs.find(\"div\", class_=\"main_leftCon\").find_all(\"table\")\n",
        "  else:\n",
        "    all_info = bs.find(\"div\", class_=\"main_leftCon\").find_all(\"p\")\n",
        "  \n",
        "  # 如果网页没有目标内容，跳过\n",
        "  if not all_info:\n",
        "    print(\"Skip2\", name)\n",
        "    continue\n",
        "  \n",
        "  # 逐条解析\n",
        "  for line in all_info:\n",
        "    info = [word for word in line.stripped_strings]\n",
        "    if not info:\n",
        "      continue\n",
        "    if info[0].find(\"城市\") != -1:\n",
        "      if len(info) >= 2:\n",
        "        # 确认城市名存在\n",
        "        info_dict[name]['city'] = info[1]\n",
        "  \n",
        "    if info[0].find(\"时间\") != -1:\n",
        "      # 匹配时间，格式****年**月**日\n",
        "      date_string = re.findall(r'\\d{4}[-/.|年]\\d{1,2}[-\\/.|月]\\d{1,2}[-/.|日]*', info[-1])\n",
        "      # debug\n",
        "      # print(info)\n",
        "      # 确认日期存在\n",
        "      if date_string:\n",
        "        # 去掉中文，转成标准格式为 ****-**-**\n",
        "        date_list = re.findall(r'\\d+',date_string[0])\n",
        "        date = '-'.join(date_list)\n",
        "        info_dict[name]['date'] = date"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpA-1rcMQQ8K",
        "colab_type": "code",
        "outputId": "2dc01494-ddf8-4dc7-bdfd-afcc68371f30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "print(info_dict[\"伊利诺伊大学香槟分校孔子学院\"])\n",
        "print(info_dict[\"北佛罗里达大学孔子学院\"])\n",
        "print(info_dict[\"南太平洋大学孔子学院\"])\n",
        "print(info_dict[\"斯科奇•欧克伯恩学院孔子课堂\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'type': '孔子学院', 'country': '美国', 'status': 'hide', 'url': 'http://www.hanban.org/confuciousinstitutes/node_40583.htm', 'city': 'NaN', 'date': 'NaN'}\n",
            "{'type': '孔子学院', 'country': '美国', 'status': 'hide', 'url': 'http://www.hanban.org/confuciousinstitutes/node_45557.htm ', 'city': 'NaN', 'date': 'NaN'}\n",
            "{'type': '孔子学院', 'country': '斐济', 'status': 'show', 'url': 'http://www.hanban.org/confuciousinstitutes/node_38667.htm', 'city': '苏瓦', 'date': '2011-02-18'}\n",
            "{'type': '孔子课堂', 'country': '澳大利亚', 'status': 'show', 'url': 'http://zhuanti.hanban.org/videolist/?cat=98&tag=cn', 'city': '朗赛斯顿', 'date': '2015-09-15'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dtrv2hjIC4mx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the information to file\n",
        "df = pd.DataFrame.from_dict(info_dict, orient='index')\n",
        "df.to_excel(\"./hanban.xlsx\", encoding='utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}